---
title: "Poison_time_dep"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
author: Aurora Hofman, Giovanni Rigolino, Paul Rognon
output:
  pdf_document:
    number_sections: yes
    toc: yes
    includes:  
params:
  stanfile: "poison_time_dep2.stan"
  iter: 5000
  adapt_delta: 0.99
  max_treedepth: 15
---
```{r, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE, warning = FALSE, error = FALSE, message = FALSE,
  tidy.opts = list(width.cutoff = 55), eval = TRUE
)
```

```{r, echo=FALSE, eval = TRUE}
# libraries
library(rstan)
library(ggplot2)
library(tidyverse)
library(kableExtra)
library(tidyverse)
library(gridExtra)
library(bayesplot)
library(lubridate)
library(reshape)

#data
load("data_report.Rdata")
```

# Introduction

As of May 15th 2020, the global death toll of the unfolding COVID-19 outbreak stands at 302 493 [1]. The global and national official death toll figures have drawn much attention and sparked vivid debate because they are at the center of the evaluation and comparison of the public health responses of national and local governments. 

Among the controversies, there is first a debate of the severity of COVID-19 and many has compared it to the yearly flu outbreaks. Brazil's President Jair Bolsonaro referred the COVID-19 as a 'little flu' and refused to implement in his country the drastic lockdown measures that many other countries have enforced [2]. 

Second, the limits of testing in terms of tests availability and accuracy have led many observers to point out the likelihood of underreporting of deaths due to the novel virus. Moreover, deaths that might be indirectly due to the COVID-19 crisis because of, for example, a collapse of the health system, are not counted in official figures. On April 26th 2020, the Financial Times headlined that global coronavirus death toll could be 60% higher than reported [3]. 

Finally, differences in testing and reporting policies across countries but also within regions have casted more doubts on the veracity of the reported figures. Belgium has reported the highest number of deaths per 100 000 inhabitants but Belgian officials also say they are counting in a way that no other country in the world is currently doing: counting deaths in hospitals and care homes, but also including deaths in care homes that are suspected, not confirmed, as COVID-19 cases [4].

There is a need of a rigorous estimation of the excess mortality in the weeks of the outbreak. A direct week by week comparison of the observed number of deaths to historical averages as done by the Financial Times analysts is a first approach but is limited as it fails to consider the variance of the number of deaths across years. 

In this report, we propose a Bayesian approach to estimate the excess mortality in the outbreak weeks through relative risk. Our model intends to provide parts of the answer to the following questions:

* Is mortality significantly higher than usual in the weeks of the outbreak?

* If confirmed, is there significant excess mortality on top of the reported COVID deaths?

<!-- * Can country to country differences in known risk factors explain the differences in mortality?  -->

# Data

## Description

Every European state has an established monitoring system of death of nationals, often centralized by the local national statistics institute. Those platforms offer a good quality and reliable source to estimate excess mortality. We gathered weekly data of the total number of deaths for weeks 1 to 18  (end of April) in the following countries and following years:

* Norway: years 2014 to 2020 [1]

* Belgium: years 2009 to 2020 [2]

* France: years 2010 to 2020 [3]

* England and Wales: years 2010 to 2020 [4]

We picked those four countries for different reasons: Belgium for its peculiar death count methodology, France and England and Wales because they are among the most affected countries and Norway because it did not have a large outbreak and therefore offers a good benchmark. The data have been retrieved from national statistic institutes of the respective countries. For each country the data were transformed to a similar structure than can be visualized in Table \ref{tab:tab1}. 

The reported COVID deaths for Norway, Belgium and France have been extracted from the Center for Systems Science and Engineering's repository at John Hopkins University Whiting School of Engineering [5]. The reported deaths for England and Wales from the Office of National Statistics [4].

xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
SUMMARY AND TODO:


OBSOBS!! THERE IS AN ERROR IN THE BELGIUM COVID SIMULATION. USING THE DATASET WITHOUT COVID. 

In Fig.\ref{fig:fig1} try and fixs the legends (matching of colour and year) It seems like 2020 has been labled as 2019. Also for england & wales some years are missing. 




Validation looks good for all countries, would be nice is the line for 2020 was in black or some colour it is possible to see. This is however not important!! 

Implementation with koronadata: Done and looking good :) Seems like a lot of countries experienced a period of less deaths after "lockdowm / focus on covid" this oculd be due to people in general beeing a lot more carefull and hence not dying from "stupid things". 

Report: 

xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx


```{r, echo=FALSE}
### Data

## loading weekly deaths data
data_england_wales <- read.csv("data/England_Wales_weekly.csv",sep = ",")
data_norway<- read.csv("data/Norway_total_death.csv", sep = ",")
data_france <- read.csv("data/data_france/weekly_deaths_france_week1_18_years2010_2020.csv", header = T, sep = ",")
data_belgium <- read.csv("data/data_belgium/weekly_deaths_belgium_week1_18_years2009_2020.csv", header = T, sep = ",")

## covid_data
data_covid <- read_csv("data/time_series_covid19_deaths_global.csv", 
    col_types = cols(Lat = col_skip(), Long = col_skip()))
data_covid <- data_covid %>% filter(`Country/Region`%in% c("Belgium","France","Norway"), is.na(`Province/State`)) %>% select(-`Province/State`)
colnames(data_covid)[1] = "Country"
data_covid <- pivot_longer(data_covid,cols = contains("/"),names_to = "date", values_to = "total_deaths")
data_covid <- data_covid %>% mutate(date=parse_date_time(date,order="mdy"),week = week(date))
data_covid <- data_covid %>% group_by(Country) %>% mutate(daily_death = c(0,diff(total_deaths)))
data_covid <- data_covid %>% group_by(Country,week) %>% mutate(weekly_death = sum(daily_death))
data_covid <- data_covid %>% select(Country,week,weekly_death) %>% distinct() %>% ungroup()
deaths_first_weeks <- data.frame(Country= c(rep("Belgium",3),rep("Norway",3),rep("France",3)),
                                 week=rep(1:3,3), weekly_death = rep(0,9))
data_covid <- rbind(data_covid,deaths_first_weeks)
data_covid <- data_covid %>% filter(week <19) %>% arrange(Country,week)

england_wales_covid <- read_csv("data/france_belgium_norway_korona_england_wales.csv", 
                                col_types = cols(belgium = col_skip(),
                                                 france = col_skip(), norway = col_skip()))
```

```{r, echo=FALSE}
## Extracting mean weekly deaths up to 2019, 2020 deaths and covid deaths by country

# England and Wales
mean_england <- rowMeans(data_england_wales[,paste("X",seq(2010,2019),sep="")])
england_2020 <- data_england_wales[,"X2020"]
england_covid <- england_wales_covid$england_wales

# Norway
mean_norway <- rowMeans(data_norway[,paste("X",seq(2014,2019),sep="")])
norway_2020 <- data_norway[,"X2020"]
norway_covid <- data_covid %>% filter(Country=="Norway")

# France
mean_france <- rowMeans(data_france[,paste("X",seq(2010,2019),sep="")])
france_2020 <- data_france[,"X2020"]
france_covid <- data_covid %>% filter(Country=="France")

# Belgium
mean_belgium <- rowMeans(data_belgium[,paste("X",seq(2009,2019),sep="")])
belgium_2020 <- data_belgium[,"X2020"]
belgium_covid <- data_covid %>% filter(Country=="Belgium")
```

```{r, echo = FALSE, eval = TRUE}
df <- data_england_wales
df <- df[,c("week","X2017", "X2018","X2019",  "X2020")]
kable(df, "latex",
  booktabs = T,
  align = "c",
  col.names = c("Week","2017", "2018","2019",  "2020"),
  caption = "\\label{tab:tab1} Number of deaths by week in England and Wales")%>%
  kable_styling(
    latex_options = c("hold_position", "condensed")
  )
```


## Visualization

### Weekly deaths

Fig.\ref{fig:fig1} show the weekly deaths from weeks 1 to 18 for each of the countries and each of the years. We observe several common patterns across countries. Firstly, they all show a downtrend with larger numbers of deaths in the first weeks of the year than in spring. Secondly, there is noise and peaks around this trend with some years being more deadly than others. 
There are very few dips in the data, the mortality can increase sharply but rearly decrease very rapidly from one week to the next. 
Earlier weeks are more often subjects to outbreaks of flu and other winter diseases than later weeks. Finally, most countries have a large peak between weeks 10 and 17 in 2020 which clearly stands out of from other years. On the contrary, Norway shows no peak. 

```{r, echo = FALSE, eval = TRUE}
### Exploratory data analysis

# Weekly deaths across years
pivot_and_plot <- function(data){
  data <- pivot_longer(data,cols = starts_with("X"),names_to = "year", values_to = "deaths")
  data$year <- gsub("X","",data$year)
  p <- ggplot(data) + geom_line(aes(x=week,y=deaths,col=year)) +
    theme(legend.text=element_text(size=4))
  return(p)
}

datasets <- list(data_england_wales,
                 data_norway,data_france,
                 data_belgium)
countries <- c("England and Wales","Norway",
               "France","Belgium")
plots <- list()

for(i in 1:length(datasets)){
  plots[[i]] <- pivot_and_plot(datasets[[i]]) + ggtitle(countries[i])
}
```

```{r, echo = FALSE, eval = TRUE, fig.cap="\\label{fig:fig1} Weekly deaths across years"}
grid.arrange(plots[[1]],plots[[2]],plots[[3]],plots[[4]],ncol=2)
```

### COVID deaths and mean weekly deaths

In Fig. \ref{fig:fig2}, we compare the 2020 weekly deaths to the COVID reported deaths summed to the mean weekly deaths. We observe for England and Wales a large difference between the two curves for weeks 13 to 18: there is excess mortality on top of the expected deaths plus reported COVID deaths. In Norway, 2020 deaths are below average up to week 13. After this the 2020 deaths are higher than the mean but still lower than COVID and mean deaths together, suggesting a lower mortality in Norway in 2020 for non COVID related deaths which COVID deaths do not compensate. Finally for Belgium and France, we observe larger 2020 deaths than mean deaths and COVID together up to week 15, suggesting again excess mortality on top of expected deaths plus reported COVID deaths. However from week 16, the mean deaths plus COVID curve is higher than 2020 deaths.

Overall in this quick exploration of our data, we find no issue or dubious data point.

```{r, echo = FALSE, eval = TRUE}
# 2020 weekly deaths, mean weekly deaths and COVID reported deaths
covid_mean_norway<-data.frame(week=seq(1:18),mean=mean_norway[1:18],`2020`=norway_2020[1:18],COVID=norway_covid$weekly_death)
covid_mean_france<-data.frame(week=seq(1:18),mean=mean_france[1:18],`2020`=france_2020[1:18],COVID=france_covid$weekly_death)
covid_mean_belgium<-data.frame(week=seq(1:18),mean=mean_belgium[1:18],`2020`=belgium_2020[1:18],COVID=belgium_covid$weekly_death)
covid_mean_england<-data.frame(week=seq(1:18),mean=mean_england[1:18],`2020`=england_2020[1:18],COVID=england_covid)

pivot_and_plot2 <- function(data){
  data <- data %>% mutate(`mean+COVID`=mean+COVID)
  data <- pivot_longer(data, cols=c("mean","mean+COVID","X2020"),names_to = "type", values_to = "deaths")
  p <- ggplot(data) + geom_line(aes(x=week,y=deaths,col=type))
    
  return(p)
}


datasets <- list(covid_mean_england,
                 covid_mean_norway,covid_mean_france,
                 covid_mean_belgium)
countries <- c("England and Wales","Norway",
               "France","Belgium")
plots2 <- list()

for(i in 1:length(datasets)){
  plots2[[i]] <- pivot_and_plot2(datasets[[i]]) + ggtitle(countries[i])
}
```

```{r, echo = FALSE, eval = TRUE, fig.cap="\\label{fig:fig2} 2020 weekly deaths, mean weekly deaths and COVID reported deaths"}
grid.arrange(plots2[[1]],plots2[[2]],plots2[[3]],plots2[[4]],ncol=2)
```


# Model 

## Excess mortality

### Statistical model

For each country separately, we approach the modelling of excess mortality by estimating the relative risk $\gamma$ understood as the ratio of weekly mortality during the COVID-19 outbreak and the weekly mortality in non-outbreak times.

$$Relative Risk_i = \gamma_i = \frac{mortality_{COV,i}}{mortality_{noCOV,i}}=\frac{\frac{O_{COV,i}}{N}}{\frac{O_{noCOV,i}}{N}} = \frac{O_{COV,i}}{O_{noCOV,i}}$$

where $O_{COV,i}$ is the observed number of deaths in week $i$ of COVID outbreak, $O_{noCOV,i}$ the number of deaths for the same week in non-outbreak times and $N$ is the population assumed stable across years.

The number of deaths $O$ is a count variable. For such variable, a commonly used statistical model is the Poisson model

$$\forall i\in\{1,...,18\}, O_{COV,i} \sim \mathcal{PO}(\lambda), \hspace{0.1cm}E(O_{COV,i}) = Var(O_{COV,i}) = \lambda$$

We have:

$$\forall i\in\{1,...,18\},O_{COV,i}= O_{noCOV,i}\cdot\gamma_i \Rightarrow E(O_{COV,i})= E(O_{noCOV,i})\gamma_i = E_i \gamma_i$$

where $E_i$ is the expected number of deaths in week $i$ in non-outbreak times. For each week $i$, we estimate $E_i$  as the historical average of number of deaths in year prior to 2020.

We therefore define the following statistical model for each country separately:

$$\forall i\in\{1,...,18\},O_{COV,i} \sim \mathcal{PO}( E_i \gamma_i)$$
In these models, a value of $\gamma_i$ larger than 1 can be interpreted as excess mortality in week $i$ with respect to non-outbreak times and a value smaller than 1 as reduced mortality. This approach to modelling mortality is handy as the estimated value is standardized to the expected number of deaths and can therefore be compared between weeks.

From the exploratory data analysis, we see that there is a clear time dependency in the weekly mortality. We therefore decompose our relative risk $\gamma_i$ betwen a fixed component $\theta_i$ and a time structured effect $\theta_{i,t}$ in our models. 
$$\gamma_i=\theta_{i}\theta_{t,i} \Rightarrow \log(\gamma_i)=\log(\theta_{i})+\log(\theta_{t,i})$$

We use an auto-regressive structure of order 1 as time structure. Our models then become:

$$\forall i\in\{1,...,18\},O_{COV,i} \sim \mathcal{PO}(E_i\gamma_i)= \mathcal{PO}(E_i\theta_i\theta_{t,i})$$

where:
$$\forall i\in\{1,...,18\},\log(\theta_{t,i}) = \alpha + \beta \log(\theta_{t,i-1}) $$

### Bayesian model

We are modelling the number of deaths $O_{COV,i}$ across weeks with a Poisson distribution that depends on the relative risk of each week $\gamma_i$. We are assuming different risks for each week but at the same time the risks share characteristics such as being expected at a value around 1 and having a larger probability towards higher values (peaks) than lower values (no trough). A convenient way to model this is using a common distribution for each of the components of $\gamma_i$, that is to use a Bayesian hierarchical model. We then propose a Bayesian hierarchichal model based on the Poisson distribution for each country separately:

$$\forall i\in\{1,...,18\},(O_{COV,i}|\theta_i,\theta_{t,i}) \sim {\mathcal{PO}(E_i \theta_i\theta_{t,i})}$$

with parameters priors:

$$(\log(\theta_{1}|\sigma),...,\log(\theta_{18}|\sigma)) \sim \mathcal{N}(0,\sigma)$$

$$\forall i\in\{1,...,18\},\log(\theta_{t,i}|\sigma_t) = \alpha + \beta \log(\theta_{t,i-1}|\sigma_t) +\epsilon, \hspace{0.15cm} \epsilon \sim \mathcal{N}(0,\sigma_t)$$


where $\sigma$, $\alpha$, $\beta$ and $\sigma_t$ are hyperparameters with hyperpriors:

$$\sigma \sim \mathcal{U}(a_{\sigma},b_{\sigma})$$
$$\alpha \sim \mathcal{N}(\mu_{\alpha},\sigma_{\alpha})$$
$$\beta \sim \mathcal{U}(a_{\beta},b_{\beta})$$
$$\sigma_t \sim \mathcal{U}(a_{\sigma_t},b_{\sigma_t})$$

## Excess mortality on top of the reported COVID deaths

To model excess mortality on top of reported COVID deaths, we will use the same approach as for the modelling of excess mortality during the COVID-19 outbreak with respect to non-outbreak times. We previously estimated the relative risk $\gamma$ understood as the ratio of weekly mortality during the COVID-19 outbreak and the weekly expected mortality in non-outbreak times. We now adjust, for each country separately, the expected mortality $\tilde{E_i}$ to account for COVID deaths.

$$Relative Risk_i = \gamma_i = \frac{O_{COV,i}}{O_{noCOV,i}+D_i}$$

where $O_{COV,i}$ is the observed number of deaths in week $i$ of COVID outbreak, $O_{noCOV,i}$ the number of deaths for the same week in non-outbreak times and $D_i$ is the reported number of deaths due to COVID in week $i$.

We have:

$$\tilde{E_i}=E_i+D_i$$
The updated statistical model is:


$$\forall i\in\{1,...,18\},O_{COV,i} \sim \mathcal{PO}(\tilde{E}_i\gamma_i)= \mathcal{PO}(\tilde{E}\theta_i\theta_{t,i})$$

where:
$$\forall i\in\{1,...,18\},\log(\theta_{t,i}) = \alpha + \beta \log(\theta_{t,i-1}) $$
The priors and hyperpriors for the Bayesian model do not change.

### Choice of priors

Our choice of priors and hyperpriors has been driven by prior knowledge or lack of it. First of all, we choose a normal distribution for $\log(\theta_i)$ with mean 0 and standard deviation the hyperparamter $\sigma$. As a result $\theta_i$ is lognormally distributed and centered at 1, the expected value for the relative risk. The lognormal distribution is particularly suited for several reasons. It has a positive support and we know $\theta_i$ must be positive. The lognormal distribution has also a positive skew, so the median of $\theta_i$ is 1 but the mean is larger and very large values are possible. It is important to have such rather heavy right tail because we know the risk can increase largely, for deadly events. On the contrary we do not need a heavy left tail because the mortality is floored by the natural mortality determined by the population demographics. For the time dependent componenet of relative risk, we make the same distributional assumption where the center of the distribution is not 1 anymore but the autoregression function estimate $\alpha+\beta\theta_{t,i-1}$, that represents the dependency on previous value.

#### Choice of hyperpriors

The choice of a uniform distribution with support $(-1,1)$ for $\beta$ is motivated by our assumption of autoregressive model of order 1 for $\log(\theta_{t,i})$. When the autoregresive process is stationary, $\beta$ is the autocorrelation between two consecutive values and must be between -1 and 1. The choice of a non informative uniform distribution reflects our lack of further knowledge on the distribution of $\beta$. We choose for $\alpha$ the normal distribution, commonly used in linear regression settings. We assume the distribution of $\alpha$ to be centered at 0 because in a stationary autoregressive model of order 1, a null constant term $\alpha$ makes a null expectation for the modelled variable:

$$\log(\theta_{t,i}) = \alpha + \beta \log(\theta_{t,i-1}) \Rightarrow E(\log(\theta_{t,i}) = \alpha + \beta E(\log(\theta_{t,i-1})) \Rightarrow \mu = \alpha + \beta \mu \Rightarrow \mu=\frac{\alpha}{1-\beta}$$
As our modelled variable $\theta{t,_i}$ is log transformed, it converts to an expectation of 1 when untransformed. We choose a small value for $\sigma_{\alpha}$, 0.2, to prevent large deviations towards extremely high risk.

Finally, we choose non-informative uniform distributions for $\sigma$ and $\sigma_t$ because we do not hold prior information on them. We define small supports, $(0,0.2)$, to again prevent large desviations towards extremely high risks, as exemplified below.

```{r}
set.seed(42)
#### Prior predictive for gamma = theta * theta_t  

# hyperparameters
sigma_a = 0
sigma_b = 0.2
alpha_mu = 0
alpha_sigma = 0.2
beta_a = -1
beta_b = 1
sigma_time_a = 0
sigma_time_b= 0.2

# simulation function
prior_pred_theta<- function(){
  sigma <- runif(1, sigma_a, sigma_b)
  while (sigma <= 0.01){
    sigma <- runif(1, sigma_a, sigma_b)
  }
  #sigma_time <- runif(1, 0.01, 25)

  sigma_time <- runif(1, sigma_time_a, sigma_time_b)
  while (sigma_time <= 0.01){
    sigma_time <- runif(1, sigma_time_a, sigma_time_b)
  }
  
  alpha <- rnorm(1, mean = alpha_mu, sd = alpha_sigma)
  beta <- runif(1,beta_a,beta_b)
  log_theta <- rnorm(18, mean = 0, sigma)
  log_theta_time <- rep(0,18)
  log_theta_time[1] <- rnorm(1, mean = 0, sigma_time)
  for (i in 2:18){
    log_theta_time[i] <- rnorm(1, mean = alpha + beta*log_theta_time[i-1], sigma_time)
  } 
  theta_return <- exp(log_theta + log_theta_time)

  return(theta_return)
}

# simulation resuls
matrix_theta <-c()
for (i in 1:30000){
  matrix_theta <- c(matrix_theta, prior_pred_theta())
}
mean_priorpred_risk <- mean(matrix_theta)
median_priorpred_risk <-median(matrix_theta)
q095_priorpred_risk <- quantile(matrix_theta,0.95)
q005_priorpred_risk <- quantile(matrix_theta,0.05)
```

We check our prior by visualizing the prior predictive distribution of the relative risk and the number of deaths. We first simulated the prior predictive distribution of the total relative risk $\gamma$ across all weeks and present the results in Fig. \ref{fig:fig3}. We see the obtained distribution is concentrated around 1, the expected value for the risk, with the majority of the density betwee 0.5 and 1.5, a reasonable range of values for the risk. The quantile 5% stands at `r round(q005_priorpred_risk,3)` and the quantile 95% at `r round(q095_priorpred_risk,3)`. The right tail is heavy which is appropriate to capture peaks.

```{r, echo = FALSE, eval = TRUE, fig.cap="\\label{fig:fig3} Density of prior predictive distribution of risk "}
#plot
matrix_theta_filt <- data.frame(risk = matrix_theta) %>% filter(risk <=quantile(matrix_theta,0.99))
ggplot(matrix_theta_filt, aes(risk))+geom_density()+xlab("total relative risk (truncated at q99%)")+ theme_light() 

```

We simulated the prior predictive distribution of the number of deaths for weeks 1 to 18 and plot the results in Fig. \ref{fig:fig4} for each country. We see the obtained distributions are roughly centered around the historical mean up to 2019. For every week, the range of values is wide, allowing for large but reasonable variations of the number of deaths. Accordingly to the idea of accomodating peaks, there is more room for variation away from the center towards higher values.

```{r}
#### Prior predictive for number of deaths  

# Simulation function
prior_pred_o<- function(mean_data){
  sigma <- runif(1, sigma_a, sigma_b)
  while (sigma <= 0.01){
    sigma <- runif(1, sigma_a, sigma_b)
  }

  sigma_time <- runif(1, sigma_a, sigma_b)
  while (sigma_time <= 0.01){
    sigma_time <- runif(1, sigma_a, sigma_b)
  }
  
  alpha <- rnorm(1, mean = alpha_mu, sd = alpha_sigma)
  beta <- runif(1,beta_a,beta_b)
  log_theta <- rnorm(length(mean_data), mean = 0, sigma)
  log_theta_time <- rep(0,length(mean_data))
  log_theta_time[1] <- rnorm(1, mean = 0, sigma_time)
  for (i in 2:length(mean_data)){
    log_theta_time[i] <- rnorm(1, mean = alpha + beta*log_theta_time[i-1], sigma_time)
  } 
  theta_return <- exp(log_theta + log_theta_time)
  O <- rep(0,length(mean_data))
  for (i in 1:length(mean_data)){
   O[i] <- rpois(1, mean_data[i]*theta_return[i])
  }
  return(O)
}
```

```{r}
# Plot function
plot_priorpred_o<-function(mean){
  matrix_O <-c()
  
  for (i in 1:10000){
    matrix_O <- rbind(matrix_O, prior_pred_o(mean))
  }
  matrix_O <- data.frame(matrix_O)
  
  df<-matrix_O %>% pivot_longer(cols=starts_with("X"),names_to = "week") 
  
  df <- df %>% group_by(week)%>% summarise(q_0.05=quantile(value,0.05),
                                  median_o=median(value),
                                  q_0.95=quantile(value,0.95)) %>% ungroup()
  df <- df %>% 
    mutate(week = as.numeric(gsub("X","",df$week)))  %>% 
    arrange(week) %>% 
    mutate(obs_mean = mean) 
  
  df <- df %>% 
    pivot_longer(cols=c(obs_mean,q_0.05,q_0.95,median_o),names_to="metric")
  
  p<-ggplot(data = df) + geom_line(aes(x=week,y=value, linetype=metric, col=metric)) +
    scale_linetype_manual(name="Metric",values= c(1,1,2,2), labels = c("Obs. mean","Sim. median", "Sim. q5%", "Sim. q95%"))  +
    scale_color_manual(name="Metric",values= c("blue","black","red","red"), labels = c("Obs. mean","Sim. median", "Sim. q5%", "Sim. q95%")) + theme_light() + theme(legend.position = "bottom")
  
  return(p)
}

datasets_mean <- list(mean_england,
                 mean_norway,mean_france,
                 mean_belgium)
countries <- c("England and Wales","Norway",
               "France","Belgium")
plots3 <- list()

for(i in 1:length(datasets_mean)){
  plots3[[i]] <- plot_priorpred_o(datasets_mean[[i]]) + ggtitle(countries[i])
}

```

```{r, echo = FALSE, eval = TRUE, fig.cap="\\label{fig:fig4} Prior predictive distribution of number of deaths"}
grid.arrange(plots3[[1]],plots3[[2]],plots3[[3]],plots3[[4]],ncol=2)
```

# Results

```{r}
### Excess mortality stan

# params lists
create_list <- function(N, E, O){
  data_list <-  list(
  N = N, 
  E = E,
  O = O,
  sigma_a = 0,
  sigma_b = 0.2,
  alpha_mu = 0,
  alpha_sigma =0.2,
  beta_a = -1,
  beta_b = 1,
  sigma_time_a = 0,
  sigma_time_b= 0.2
  )
  return(data_list)
}

data_list_england_wales <- create_list( length(mean_england),mean_england,england_2020 )
data_list_norway <- create_list(length(mean_norway), mean_norway, norway_2020)
data_list_france <- create_list(length(mean_france), mean_france, france_2020)
data_list_belgium <- create_list(length(mean_belgium), mean_belgium, belgium_2020)
```

```{r, eval = FALSE}
load("data_for_stan.RData")

# stan run. run in Google Colab
risk_england_wales <- stan(params$stanfile, iter = params$iter, chains = 3,
    data = data_list_england_wales, seed = 1, control = list(adapt_delta = params$adapt_delta, max_treedepth = params$max_treedepth))
  
risk_norway <- stan(params$stanfile, iter = params$iter, chains = 3,
    data = data_list_norway, seed = 1, control = list(adapt_delta = params$adapt_delta, max_treedepth = params$max_treedepth))

risk_france <- stan(params$stanfile, iter = params$iter, chains = 3,
    data = data_list_france, seed = 1, control = list(adapt_delta = params$adapt_delta, max_treedepth = params$max_treedepth))
  
risk_belgium <- stan(params$stanfile, iter = params$iter, chains = 3,
    data = data_list_belgium, seed = 1, control = list(adapt_delta = params$adapt_delta, max_treedepth = params$max_treedepth))

```


```{r}
### Excess mortality on top of the reported COVID deaths stan
# params lists

data_list_england_wales_covid <- create_list( length(mean_england),
                                              mean_england+england_covid,
                                              england_2020 )
data_list_norway_covid <- create_list(length(mean_norway), 
                                      mean_norway + norway_covid$weekly_death, 
                                      norway_2020)
data_list_france_covid <- create_list(length(mean_france), 
                                      mean_france+france_covid$weekly_death, 
                                      france_2020)
data_list_belgium_covid <- create_list(length(mean_belgium), 
                                       mean_belgium + belgium_covid$weekly_death, 
                                       belgium_2020)
save.image("data_for_stan.RData")
```

```{r, eval = FALSE}
load("data_for_stan.RData")

# stan run. run in Google Colab
risk_england_wales_covid <- stan(params$stanfile, iter = params$iter, chains = 3,
    data = data_list_england_wales_covid, seed = 1, control = list(adapt_delta = params$adapt_delta, max_treedepth = params$max_treedepth))
  
risk_norway_covid <- stan(params$stanfile, iter = params$iter, chains = 3,
    data = data_list_norway_covid, seed = 1, control = list(adapt_delta = params$adapt_delta, max_treedepth = params$max_treedepth))
  
  
risk_france_covid <- stan(params$stanfile, iter = params$iter, chains = 3,
    data = data_list_france_covid, seed = 1, control = list(adapt_delta = params$adapt_delta, max_treedepth = params$max_treedepth))
  
risk_belgium_covid <- stan(params$stanfile, iter = params$iter, chains = 3,
    data = data_list_belgium, seed = 1, control = list(adapt_delta = params$adapt_delta, max_treedepth = params$max_treedepth))
```


## Convergence

### Excess deaths
    
We check the convergence of each of our four models (one per country) by checking the Rhat values for all parameters, plotting the chains traces and autorcorrations in chains. Table \ref{tab:tab3} gathers the maximum rhat value in each model. All the values are below 1.01 indicating satisfactory convergence. In Fig.\ref{fig:fig5} and Fig. \ref{fig:fig6} we plot the chain traces and autocorrelation plots for four parameters in the England and Wales model as an example. We can see the chains mix well. There is a bit of autocorrelation in the plots of log_theta[16] but it is small and there is no autocorrelation for the other paramaters.

```{r,eval=FALSE}
load("stan_output.Rdata")
print(risk_england_wales)
print(risk_belgium)
print(risk_france)
print(risk_norway)
```

```{r}
df<-data.frame(country=c("England and Wales", "Norway", "Belgium", "France"),
               Max_rhat = c(max(rhat(risk_england_wales)),
                            max(rhat(risk_norway)),
                            max(rhat(risk_belgium)),
                            max(rhat(risk_france))))
kable(df, "latex",
  booktabs = T,
  align = "c",
  digit = 3,
  col.names = c("Country","Max rhat"),
  caption = "\\label{tab:tab3} Max Rhat in excess deaths models")%>%
  kable_styling(
    latex_options = c("hold_position", "condensed")
  )
```

```{r, echo = FALSE, eval = TRUE, fig.cap="\\label{fig:fig5} Chains traces for a sample of parameters from England and Wales excess deaths model"}
# England and Wales trace
mcmc_trace(risk_england_wales,
           pars = c("log_theta[16]","log_theta_time[7]","alpha","sigma_time"))
```

```{r, echo = FALSE, eval = TRUE, fig.cap="\\label{fig:fig6} Autocorrlation plots for a sample of parameters from England and Wales excess deaths model"}
# England and Wales ACF
mcmc_acf_bar(risk_england_wales,
           pars = c("log_theta[16]","log_theta_time[7]","alpha","sigma_time"))
```

```{r, eval=FALSE}
# Norway
mcmc_acf_bar(risk_norway,
           pars = c("log_theta[16]","log_theta_time[7]","alpha","sigma_time"))

mcmc_trace(risk_norway,
           pars = c("log_theta[16]","log_theta_time[7]","alpha","sigma_time"))

# Belgium
mcmc_acf_bar(risk_belgium,
           pars = c("log_theta[16]","log_theta_time[7]","alpha","sigma_time"))

mcmc_trace(risk_belgium,
           pars = c("log_theta[16]","log_theta_time[7]","alpha","sigma_time"))

# France
mcmc_acf_bar(risk_france,
           pars = c("log_theta[16]","log_theta_time[7]","alpha","sigma_time"))

mcmc_trace(risk_france,
           pars = c("log_theta[16]","log_theta_time[7]","alpha","sigma_time"))

```


### Excess deaths on top of the reported COVID deaths
    
We check again the convergence of each of our four models (one per country) by checking the Rhat values for all parameters, plotting the chains traces and autocorrations in chains. Table \ref{tab:tab4} gathers the maximum rhat value in each model. All the values are a bit larger below strictly 1.02 indicating satisfactory convergence. In Fig.\ref{fig:fig7} and \ref{fig:fig8} we plot the chain traces and autocorrelation plots for four parameters in the Belgium model as an example. We can see the chains mix well. There is a bit of autocorrelation in the plots of log_theta[1] but it is small and there is no autocorrelation for the other paramaters.

```{r,eval=FALSE}
load("stan_output_covid.Rdata")
print(risk_england_wales_covid)
print(risk_belgium_covid)
print(risk_france_covid)
print(risk_norway_covid)
```

```{r}
df<-data.frame(country=c("England and Wales", "Norway", "Belgium", "France"),
               Max_rhat = c(max(rhat(risk_england_wales_covid)),
                            max(rhat(risk_norway_covid)),
                            max(rhat(risk_belgium_covid)),
                            max(rhat(risk_france_covid))))
kable(df, "latex",
  booktabs = T,
  align = "c",
  digit = 3,
  col.names = c("Country","Max rhat"),
  caption = "\\label{tab:tab4} Max Rhat in models excess deaths on top of the reported COVID deaths")%>%
  kable_styling(
    latex_options = c("hold_position", "condensed")
  )
```

```{r, echo = FALSE, eval = TRUE, fig.cap="\\label{fig:fig7} Chains traces for a sample of parameters from Belgium excess deaths on top of the reported COVID deaths model"}
# England and Wales trace
mcmc_trace(risk_belgium_covid,
           pars = c("log_theta[1]","log_theta_time[17]","beta","sigma_time"))
```

```{r, echo = FALSE, eval = TRUE, fig.cap="\\label{fig:fig8} Autocorrlation plots for a sample of parameters from Belgium excess deaths on top of the reported COVID deaths model"}
# England and Wales ACF
mcmc_acf_bar(risk_belgium_covid,
           pars = c("log_theta[1]","log_theta_time[17]","beta","sigma_time"))
```

```{r, eval=FALSE}
# Norway
mcmc_acf_bar(risk_norway_covid,
           pars = c("log_theta[1]","log_theta_time[17]","beta","sigma_time"))

mcmc_trace(risk_norway_covid,
           pars = c("log_theta[1]","log_theta_time[17]","beta","sigma_time"))

# England and Wales
mcmc_acf_bar(risk_england_wales_covid,
           pars = c("log_theta[1]","log_theta_time[17]","beta","sigma_time"))

mcmc_trace(risk_england_wales_covid,
           pars = c("log_theta[1]","log_theta_time[17]","beta","sigma_time"))

# France
mcmc_acf_bar(risk_france_covid,
           pars = c("log_theta[1]","log_theta_time[17]","beta","sigma_time"))

mcmc_trace(risk_france_covid,
           pars = c("log_theta[1]","log_theta_time[17]","beta","sigma_time"))

```

## Validation

To validate our model we work on the posterior predictive distribution. We have little information to compare that distribution to actual data as we have only one data per week in 2020. For each country and for each week, we compare the 2020 value to median and quantiles 5% and 95% of our posterior predictive distribution. In this validation procedure, a good model would be a model for which the 2020 data falls between the two quantiles for all weeks and close to the median. Aslo none of the simulations should deviate very far from the others. 

<!-- I changed form prior predictive to posterior predictive -->

```{r}
# function for extracting simulated data
extract_simulations <- function(risk_data){
  sim_1<- rstan::extract(risk_data, "sim[1]")[[1]]
  sim_2<- rstan::extract(risk_data, "sim[2]")[[1]]
  sim_3<- rstan::extract(risk_data, "sim[3]")[[1]]
  sim_4<- rstan::extract(risk_data, "sim[4]")[[1]]
  sim_5<- rstan::extract(risk_data, "sim[5]")[[1]]
  sim_6<- rstan::extract(risk_data, "sim[6]")[[1]]
  sim_7<- rstan::extract(risk_data, "sim[7]")[[1]]
  sim_8<- rstan::extract(risk_data, "sim[8]")[[1]]
  sim_9<- rstan::extract(risk_data, "sim[9]")[[1]]
  sim_10<- rstan::extract(risk_data, "sim[10]")[[1]]
  sim_11<- rstan::extract(risk_data, "sim[11]")[[1]]
  sim_12<- rstan::extract(risk_data, "sim[12]")[[1]]
  sim_13<- rstan::extract(risk_data, "sim[13]")[[1]]
  sim_14<- rstan::extract(risk_data, "sim[14]")[[1]]
  sim_15<- rstan::extract(risk_data, "sim[15]")[[1]]
  sim_16<- rstan::extract(risk_data, "sim[16]")[[1]]
  sim_17<- rstan::extract(risk_data, "sim[17]")[[1]]
  sim_18<- rstan::extract(risk_data, "sim[18]")[[1]]
  posterior_chains <- tibble(sim_1, sim_2, sim_3, sim_4, sim_5, sim_6, sim_7, sim_8, sim_9, sim_10, sim_11, sim_12, sim_13, sim_14, sim_15, sim_16,sim_17,sim_18)
  return(posterior_chains)
}

# function for validation plot
plot_validation <- function(posterior_chain, deaths_2020, lim=14){
  set.seed(43)
  df0<- posterior_chain %>% pivot_longer(cols=starts_with("sim"),names_to = "week") 
  
  df0 <- df0 %>% group_by(week)%>% summarise(Simq0.05=quantile(value,0.05),
                                  median_o=median(value),
                                  Simq0.95=quantile(value,0.95)) %>% ungroup()
  
  df0 <- df0 %>% 
    mutate(week = as.numeric(gsub("sim_","",df0$week)))  %>% 
    arrange(week) %>% 
    mutate(obs2020 = deaths_2020, bef_af = as.factor(week > lim))
  
  df <- df0 %>% pivot_longer(cols=c(obs2020,Simq0.05,Simq0.95),names_to="metric")
  
  levels(df$bef_af) <- c(paste0("Weeks 1-",lim), paste0("Weeks ",lim+1,"-18"))
  
  posterior_chains_mini <-data.frame(t(posterior_chain[sample(1:nrow(posterior_chain),10),]), 
                                     week=seq(1:18), bef_af = as.factor(seq(1:18) > lim))
  Molten <- melt(posterior_chains_mini, id.vars = c("week","bef_af"))
  Molten$Simulation <- gsub("X","",Molten$variable)
  
  levels(Molten$bef_af) <- c(paste0("Weeks 1-",lim), paste0("Weeks ",lim+1,"-18"))
  
  p <- ggplot()+ geom_line(data=Molten, aes(x = week, y = value, colour = Simulation)) + 
    geom_line(data = df,aes(x=week,y=value, linetype=metric), col="black",size=0.7) + 
    facet_wrap(~bef_af, scales = "free")+ theme_light() + theme(legend.position = "bottom")
  return(list(plot=p,comp_med=df0 %>% select(c(obs2020,median_o))))
}
```


### Excess deaths

In Fig.\ref{fig:fig9}, \ref{fig:fig9b}, \ref{fig:fig9c} and  \ref{fig:fig9d} we plot the 2020 deaths along with 10 simulations of posterior predictive distribution and the 5% and 95% quantiles computed on the posterior predictive for each week. We see that the 2020 deaths data falls well between the quantiles and in the mid of the simulated trajectories. In Table \ref{tab:tab5} and \ref{tab:tab6}, we compare the 2020 deaths to the median of the simulations of the posterior predictive for each week. We see that for all the countries, the two values are very close.

```{r}
posterior_chains_england <- extract_simulations(risk_england_wales)
posterior_chains_norway <- extract_simulations(risk_norway)
posterior_chains_france <- extract_simulations(risk_france)
posterior_chains_belgium <- extract_simulations(risk_belgium)

val_plot_england <- plot_validation(posterior_chains_england,england_2020,lim=14)$plot + 
  ggtitle("England and Wales")

val_plot_belgium <- plot_validation(posterior_chains_belgium,belgium_2020,lim=13)$plot + 
  ggtitle("Belgium")

val_plot_france <- plot_validation(posterior_chains_france,france_2020,lim=13)$plot + ggtitle("France") 


val_plot_norway <- plot_validation(posterior_chains_norway,norway_2020,lim=13)$plot + ggtitle("Norway") 

```

```{r, echo = FALSE, eval = TRUE, fig.cap="\\label{fig:fig9} Validation of excess deaths model"}
val_plot_england
```


```{r, echo = FALSE, eval = TRUE, fig.cap="\\label{fig:fig9b} Validation of excess deaths model continued"}
val_plot_norway
```


```{r, echo = FALSE, eval = TRUE, fig.cap="\\label{fig:fig9c} Validation of excess deaths model continued"}
val_plot_belgium
```


```{r, echo = FALSE, eval = TRUE, fig.cap="\\label{fig:fig9d} Validation of excess deaths model continued"}
val_plot_france
```


```{r}
df1 <- cbind(seq(1:18),plot_validation(posterior_chains_england,england_2020,lim=14)$comp_med,
      plot_validation(posterior_chains_belgium,belgium_2020,lim=13)$comp_med)
df2 <- cbind(seq(1:18),plot_validation(posterior_chains_france,france_2020,lim=13)$comp_med,
      plot_validation(posterior_chains_norway,norway_2020,lim=13)$comp_med)

kable(df1, "latex",
  booktabs = T,
  align = "c",
  digit = 0,
  col.names = c("week",rep(c("Obs. 2020","Sim. Median"),2)),
  caption = "\\label{tab:tab5} Values observed in 2020 and simulations of excess deaths model")%>%
  kable_styling(
    latex_options = c("hold_position", "condensed")
  ) %>% 
  add_header_above(c(" " = 1, "England and Wales" = 2, "Belgium" = 2))


kable(df2, "latex",
  booktabs = T,
  align = "c",
  digit = 0,
  col.names = c("week",rep(c("Obs. 2020","Sim. Median"),2)),
  caption = "\\label{tab:tab6} Values observed in 2020 and simulations of excess deaths model")%>%
  kable_styling(
    latex_options = c("hold_position", "condensed")
  ) %>% 
  add_header_above(c(" " = 1, "France" = 2, "Norway" = 2))
```


### Excess deaths on top of the reported COVID deaths

In Fig.\ref{fig:fig10}, \ref{fig:fig10b}, \ref{fig:fig10c} and \ref{fig:fig10d} we plot again the 2020 deaths along with 10 simulations of posterior predictive distribution and the 5% and 95% quantiles computed on the posterior predictive for each week. We see that the 2020 deaths data falls well between the quantiles and in the mid of the simulated trajectories. In Table \ref{tab:tab7} and \ref{tab:tab8}, we compare the 2020 deaths to the median of the simulations of the posterior predictive for each week. We see that for all the countries, the two values are very close.

```{r}
posterior_chains_england_covid <- extract_simulations(risk_england_wales_covid)
posterior_chains_norway_covid <- extract_simulations(risk_norway_covid)
posterior_chains_france_covid <- extract_simulations(risk_france_covid)
posterior_chains_belgium_covid <- extract_simulations(risk_belgium_covid)

val_plot_england_covid <- plot_validation(posterior_chains_england_covid,england_2020,lim=14)$plot + 
  ggtitle("England and Wales")

val_plot_belgium_covid <- plot_validation(posterior_chains_belgium_covid,belgium_2020,lim=13)$plot + 
  ggtitle("Belgium")

val_plot_france_covid <- plot_validation(posterior_chains_france_covid,france_2020,lim=13)$plot + ggtitle("France") 


val_plot_norway_covid <- plot_validation(posterior_chains_norway_covid,norway_2020,lim=13)$plot + ggtitle("Norway") 

```

```{r, echo = FALSE, eval = TRUE, fig.cap="\\label{fig:fig10} Validation of excess deaths on top of the reported COVID deaths model"}
val_plot_england_covid
```


```{r, echo = FALSE, eval = TRUE, fig.cap="\\label{fig:fig10b} Validation of excess deaths on top of the reported COVID deaths model continued"}
val_plot_norway_covid
```


```{r, echo = FALSE, eval = TRUE, fig.cap="\\label{fig:fig10c} Validation of excess deaths on top of the reported COVID deaths model continued"}
val_plot_belgium_covid
```


```{r, echo = FALSE, eval = TRUE, fig.cap="\\label{fig:fig10d} Validation of excess deaths on top of the reported COVID deaths modelcontinued"}
val_plot_france_covid
```


```{r}
df_covid1 <- cbind(seq(1:18),plot_validation(posterior_chains_england_covid,england_2020,lim=14)$comp_med,
      plot_validation(posterior_chains_belgium_covid,belgium_2020,lim=13)$comp_med)
df_covid2 <- cbind(seq(1:18),plot_validation(posterior_chains_france_covid,france_2020,lim=13)$comp_med,
      plot_validation(posterior_chains_norway_covid,norway_2020,lim=13)$comp_med)

kable(df_covid1, "latex",
  booktabs = T,
  align = "c",
  digit = 0,
  col.names = c("week",rep(c("Obs. 2020","Sim. Median"),2)),
  caption = "\\label{tab:tab7} Values observed in 2020 and simulations median of excess deaths on top of the reported COVID deaths model")%>%
  kable_styling(
    latex_options = c("hold_position", "condensed")
  ) %>% 
  add_header_above(c(" " = 1, "England and Wales" = 2, "Belgium" = 2))

kable(df_covid2, "latex",
  booktabs = T,
  align = "c",
  digit = 0,
  col.names = c("week",rep(c("Obs. 2020","Sim. Median"),2)),
  caption = "\\label{tab:tab8} Values observed in 2020 and simulations median of excess deaths on top of the reported COVID deaths model")%>%
  kable_styling(
    latex_options = c("hold_position", "condensed")
  ) %>% 
  add_header_above(c(" " = 1, "France" = 2, "Norway" = 2))

```

```{r,eval=FALSE}
save.image("data_report.Rdata")
```


## Inferential results

The countries will be evaluated one by one starting with England and Wales. 

<!-- TBD -->

<!-- ```{r} -->
<!-- p1<-mcmc_areas(risk_england_wales, -->
<!--            pars = c("log_theta[1]","log_theta_time[13]","log_theta_time[14]","log_theta_time[18]")) + ggtitle("England and Wales") -->
<!-- p2<-mcmc_areas(risk_belgium, -->
<!--            pars = c("log_theta[1]","log_theta_time[12]","log_theta_time[14]","log_theta_time[18]")) + ggtitle("Belgium") -->
<!-- p3<-mcmc_areas(risk_france, -->
<!--            pars = c("log_theta[1]","log_theta_time[12]","log_theta_time[14]","log_theta_time[18]")) + ggtitle("France") -->
<!-- p4<-mcmc_areas(risk_norway, -->
<!--            pars = c("log_theta[1]","log_theta_time[12]","log_theta_time[14]","log_theta_time[18]")) + ggtitle("Norway") -->
<!-- grid.arrange(p1,p2,p3,p4,ncol=2) -->
<!-- ``` -->

```{r, include=FALSE}
create_CI_theta_vec <- function(risk_data, N){
  fit<-summary(risk_data)
  results <- as.data.frame(fit$summary)

  CI_upper <- exp(results$`97.5%`[1:N] + results$`97.5%`[(N+1):(2*N)])
  CI_lower <- exp(results$`2.5%`[1:N] +results$`2.5%`[(N+1):(2*N)])

  theta <- exp(results$mean[1:N] +results$mean[(N+1):(2*N)])
  week <- seq(1:N)
  data <- data.frame(week, CI_upper, CI_lower, theta)
  return(data)

}
plot_risk <- function(data, country_name){
  g<- ggplot(data = data, aes(x = week, y = theta)) + geom_point() + geom_line(lty = 2) +
    geom_line(aes(week, CI_lower), col = "blue", lty = 2) +
    geom_line(aes(week, CI_upper), col = "blue", lty = 2) +
    geom_hline(yintercept = 1, col = "red")+
    ggtitle(country_name)
  ggsave(paste0("output_",country_name,".png"))
  return(g)
}
```


### England and Wales
```{r, eval = FALSE, include=FALSE}
data_england_wales <- create_CI_theta_vec(risk_england_wales, length(mean_england))
plot_risk(data_england_wales, "England and Wales")
```

```{r, eval = FALSE, include=FALSE}
data_england_wales_covid <- create_CI_theta_vec(risk_england_wales_covid, length(mean_england))
plot_risk(data_england_wales_covid, "England and Wales")
```

In Fig.\ref{fig:fig11} one can see the evolution if the estimated values of the risk for England and Wales. One can clearly see that there is a dramatic increase in risk as the covid-19 pandemic evolves. 
```{r, eval = TRUE, fig.cap="\\label{fig:fig11} Poisson model estimates for England and Wales",out.extra = "", fig.pos = 'h!', fig.align="center", out.height="50%"}
 knitr::include_graphics("output_England and Wales.png")
```




```{r, eval = TRUE, fig.cap="\\label{fig:fig12} Poisson model estimates for England and Wales including covid deaths",out.extra = "", fig.pos = 'h!', fig.align="center", out.height="50%"}
 knitr::include_graphics("output_England_and_Wales_covid.png")
```
### Norway

```{r}
data_norway <- create_CI_theta_vec(risk_norway, length(mean_norway))
plot_risk(data_norway, "Norway")
```
```{r, eval = FALSE}
data_norway_covid <- create_CI_theta_vec(risk_norway_covid, length(mean_england))
plot_risk(data_norway_covid, "Norway")
```
```{r, eval = TRUE, fig.cap="\\label{fig:fig6} Negative binomial model estimates for Norway",out.extra = "", fig.pos = 'h!', fig.align="center", out.height="50%"}
knitr::include_graphics("output_Norway.png")
```

### France
```{r}
data_france <- create_CI_theta_vec(risk_france, length(mean_france))
plot_risk(data_france, "France")
```
```{r}
data_france_covid <- create_CI_theta_vec(risk_france_covid, length(mean_france))
plot_risk(data_france_covid, "France")
```
```{r, eval = TRUE, fig.cap="\\label{fig:fig9} Negative binomial model estimates for France",out.extra = "", fig.pos = 'h!', fig.align="center", out.height="50%"}
knitr::include_graphics("output_France.png")
```
### Belgium
```{r}
data_belgium <- create_CI_theta_vec(risk_belgium, length(mean_belgium))
plot_risk(data_belgium, "Belgium")
```
```{r}
data_belgium_covid <- create_CI_theta_vec(risk_belgium_covid, length(mean_belgium))
plot_risk(data_belgium_covid, "Belgium")
```
```{r, eval = TRUE, fig.cap="\\label{fig:fig10} Negative binomial model estimates for Belgium",out.extra = "", fig.pos = 'h!', fig.align="center", out.height="50%"}
knitr::include_graphics("output_Belgium.png")
```


```{r}
# Save output
save.image("excess_deaths_output.Rdata")
```


### With Covid

```{r}
data_norway_covid <- create_CI_theta_vec(risk_norway_covid, length(mean_norway))
plot_risk(data_norway_covid, "Norway")

```
```{r}
data_belgium_covid <- create_CI_theta_vec(risk_belgium_covid, length(mean_belgium))
plot_risk(data_belgium_covid, "Belgium")

```

# Conclusion

<!-- TBD -->

# Data sources

[1] Statistics Norway, https://www.ssb.no/statbank/table/07995/

[2] Statbel, https://statbel.fgov.be/fr/nouvelles/mortalite-jusquau-3-mai

[3] Institut National de Statistiques et Études Économiques, https://www.insee.fr/fr/statistiques/4487854, https://www.insee.fr/fr/information/4190491

[4] Office of National Statistics, https://www.ons.gov.uk/peoplepopulationandcommunity/birthsdeathsandmarriages/deaths/datasets/weeklyprovisionalfiguresondeathsregisteredinenglandandwales

[5] https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv